# Stochastic gradient descent (SGD) with Ridge regularization, without using libraries

An implementation of stochastic gradient descent (SGD) using Ridge regularization without any statistical or machine learning library. All steps are done by hand, using matrix operations as much as possible.

## Setting up the project

- Install Python 3.6 or higher
- Go into this repository's directory
- Create a Python [environment](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment):
  `python3 -m venv env`
- Activate the environmnet: `source env/bin/activate` (Linux/Mac) or `.\env\Scripts\activate` (Windows)
- Upgrade pip: `python -m pip install --upgrade pip`
- Install the Python packages: `pip install -r requirements.txt`
