{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20c791c-4ee2-411e-9396-5b9d998db793",
   "metadata": {},
   "source": [
    "# Programming Assignment 3 - Logistic regression without libraries\n",
    "\n",
    "CAP 5625 Computational Foundations of AI - Fall 2021 - Dr. DeGiorgio\n",
    "<br>Christian Garbin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1b11f-d622-4bb4-bce0-a5bb166338b5",
   "metadata": {},
   "source": [
    "Instructions to run the code are available in the README.md file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073608b-939f-4d11-a13b-3c06be43abb1",
   "metadata": {},
   "source": [
    "# Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc3822-c014-42df-a448-e198c5af2b9f",
   "metadata": {},
   "source": [
    "Import the Python modules we use in the notebook and configure the Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de75063-2184-4072-8ce8-875140fe9065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import and set up the graphing environment\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make plots legible and focus on trends (not specific values)\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=1.5, rc={\"lines.linewidth\": 2})\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99813544-60f4-4a67-ba08-26a57edaf269",
   "metadata": {},
   "source": [
    "Import our logistic regression module and the utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522223ab-232a-46b3-960b-30a654c95b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ddd3c-e817-40e7-96f2-5de59b855623",
   "metadata": {},
   "source": [
    "# Ancillary code and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df877f-ce13-4ec5-ae18-2b026f86df62",
   "metadata": {},
   "source": [
    "Run the automated tests to verify the code works as intended before we start the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddbe6fa-a714-4a35-a22e-23953ca40608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./test')\n",
    "import test_all\n",
    "# Set to true to see each test result\n",
    "test_all.test_all(False, './data')\n",
    "print('All tests passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21a10f-457a-48af-b142-f728c820bc09",
   "metadata": {},
   "source": [
    "Constants used in the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90aaabf6-cb1d-4149-9b41-e0c2176a7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDAS_TO_TEST = [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]\n",
    "NUM_TESTS = len(LAMBDAS_TO_TEST)\n",
    "LR = 0.00001\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e5bc9-c31e-4abe-9bc9-b130e81dbd77",
   "metadata": {},
   "source": [
    "Read the dataset and prepare it by encoding categorical columns, standardizing if asked to do so. Note that there is no caching. For a larger dataset we should probably cache it.\n",
    "\n",
    "Also set constants that depend on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4b1573-61ca-4430-96fa-182336decc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = []\n",
    "CATEGORIES = []\n",
    "\n",
    "def read_dataset(standardize: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    global FEATURE_NAMES, CATEGORIES\n",
    "    \n",
    "    x, y, FEATURE_NAMES, CATEGORIES = utils.read_dataset(\n",
    "        './data/TrainingData_N183_p10.csv', hot_encode=True)\n",
    "\n",
    "    if standardize:\n",
    "        utils.scale(x)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13613359-8ab5-4a9c-8c37-69310a073bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_dataset(standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3072242-0a89-42b5-8e96-f444c58c133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/TrainingData_N183_p10.csv')\n",
    "\n",
    "# Split the features (input) from the output, assumming the last column is the output\n",
    "features = dataset.iloc[:, :-1]\n",
    "output = dataset.iloc[:, -1:]\n",
    "\n",
    "# If requested, convert the output variable from categorical to indicators (hot encoding)\n",
    "# Note that it assumes that the output is a single column\n",
    "output = output.iloc[:, 0].str.get_dummies()\n",
    "\n",
    "# Convert to NumPy arrays in preparation to manipulate it\n",
    "x = features.to_numpy()\n",
    "y = output.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14b751f8-0847-436f-93c0-5201f6ab3955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['African', 'EastAsian', 'European', 'NativeAmerican', 'Oceanian']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42badc4d-9fad-41c9-a521-c79292aace8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca500878-ed53-455c-bcdc-744528d37d62",
   "metadata": {},
   "source": [
    "# Deliverable 1 - effect of lambda on coefficients\n",
    "\n",
    "> _Illustrate the effect of the tuning parameter on the inferred ridge regression coefficients by generating five plots (one for each of the K = 5 ancestry classes) of 10 lines (one for each of the p = 10 features), with the y-axis as β̂jk, j = 1,2, ... ,10 for the graph of class k, and x-axis the corresponding log-scaled tuning parameter value log10(λ) that generated the particular β̂jk._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc9f8b-48bf-4b28-b192-ca5b8c416f22",
   "metadata": {},
   "source": [
    "Perform logistic regression with the different lambda values (takes several seconds to complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e5447-d34c-4c3d-9cb9-626826951dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "for lmbda in LAMBDAS_TO_TEST:\n",
    "    x, y = read_dataset()\n",
    "    b = logistic.fit(x, y, lr=LR, lmbda=lmbda, iterations=100_000)\n",
    "    betas.append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636e9e2-6c59-42b1-aa49-ee20c48917f6",
   "metadata": {},
   "source": [
    "Plot the results, showing how larger values of lambda decrease the coefficients (betas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221a3da-3752-4f9b-b3d9-71b8627cd20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_betas(betas: np.ndarray, title: str):\n",
    "    # Create a DataFrame in the long format\n",
    "    df = pd.DataFrame(np.squeeze(betas), columns=FEATURE_NAMES,\n",
    "                      index=LAMBDAS_TO_TEST)\n",
    "    df = df.stack().reset_index()\n",
    "    df.columns = ['Lambda', 'Feature', 'Standardized Coefficients']\n",
    "    \n",
    "    # Plot it\n",
    "    fig, ax = plt.subplots(figsize=(12, 8));\n",
    "    sns.lineplot(ax=ax, y='Standardized Coefficients', x='Lambda',\n",
    "                 hue='Feature', data=df)\n",
    "    ax.set_xscale('log')\n",
    "    plt.legend(bbox_to_anchor=(1.04,1), loc='upper left')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "plot_betas(betas, 'Coefficients x lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4b4e42-32ed-4ef8-a373-fc00c728afb3",
   "metadata": {},
   "source": [
    "# Deliverable 2 - effect of lambda on MSE (with cross validation)\n",
    "\n",
    "> _Illustrate the effect of the tuning parameter on the cross validation error by generating a plot with the y-axis as CV(5) error, and the x-axis the corresponding log-scaled tuning parameter value log10(λ) that generated the particular CV(5) error._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05654bd8-3dc7-4231-9a95-7ff37b02a865",
   "metadata": {},
   "source": [
    "Perform logistic regression with the different lambda values and cross validation (takes several seconds to complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a0a29-02ac-42ef-aaf4-55b9b86a9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.zeros(NUM_TESTS)\n",
    "for i, lmbda in enumerate(LAMBDAS_TO_TEST):\n",
    "    x, y = read_dataset(standardize=False)\n",
    "    fold_mse = np.zeros(NUM_FOLDS)\n",
    "    for fold in range(1, NUM_FOLDS+1, 1):\n",
    "        x_train, x_val, y_train, y_val = utils.split_fold(x, y,\n",
    "                                                          num_folds=NUM_FOLDS,\n",
    "                                                          fold=fold)\n",
    "        utils.scale_val(x_train, x_val)\n",
    "        utils.center_val(y_train, y_val)\n",
    "\n",
    "        model = logistic.fit(x_train, y_train, lr=LR, lmbda=lmbda, iterations=20_000)\n",
    "        predictions = logistic.predict(x_val, model)\n",
    "        fold_mse[fold-1] = utils.mse(y_val, predictions)\n",
    "    mse[i] = fold_mse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5171df3-b744-44f4-ae77-88bed756ff24",
   "metadata": {},
   "source": [
    "Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5716f5f-4a0d-4836-b891-07b8ba445d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse(mse: np.ndarray, title: str):\n",
    "    # Create a DataFrame in the long format to plot\n",
    "    df2 = pd.DataFrame([LAMBDAS_TO_TEST, mse]).T\n",
    "    df2.columns = ['Lambda', 'MSE']\n",
    "    \n",
    "    # Plot it\n",
    "    fig, ax = plt.subplots(figsize=(12, 8));\n",
    "    sns.lineplot(ax=ax, y='MSE', x='Lambda', data=df2)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_title(title)\n",
    "\n",
    "plot_mse(mse, 'Effect of lambda on MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd701e1-c9d5-48b5-97e4-025e188f1172",
   "metadata": {},
   "source": [
    "# Deliverable 3 - the lambda with the smallest MSE\n",
    "\n",
    "> _Indicate the value of λ value (sic) that generated the smallest CV(5) error._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15879b-8b07-4158-81ba-2da7aa5c3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_mse_index = mse.argmin()\n",
    "smallest_mse_lambda = LAMBDAS_TO_TEST[smallest_mse_index]\n",
    "print(f'The lambda with the smallest MSE is {smallest_mse_lambda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d87ed-961a-4210-a98c-faee16bedaf9",
   "metadata": {},
   "source": [
    "# Deliverable 4 - model parameters for the lambda with the smallest MSE\n",
    "\n",
    "> _Given the optimal λ, retrain your model on the entire dataset of N = 183 observations to obtain an estimate of the (p + 1) × K model parameter matrix as B̂ and make predictions of the probability for each of the K = 5 classes for the 111 test individuals located in `TestData_N111_p10.csv`._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab940f0-48c4-4864-a3df-84dbeecd4d2b",
   "metadata": {},
   "source": [
    "Train a model with the lambda that resulted in the smallest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09ff8b-46c9-4d05-bb82-9e47da9ddbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_dataset()\n",
    "betas4 = logistic.fit(x, y, lr=LR, lmbda=smallest_mse_lambda, iterations=100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78bdc70-95ad-4441-92c1-535101352848",
   "metadata": {},
   "source": [
    "Show the coefficients for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c68b9d-158d-4119-b0ba-fde45121e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, beta in zip(FEATURE_NAMES, betas4.flatten()):\n",
    "    print(f'{feature:>10}: {beta:7.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b88c69-b467-451b-aa9b-465d66d1498a",
   "metadata": {},
   "source": [
    "# Deliverable 5 - compare with expected real-world results\n",
    "\n",
    "> How do the class label probabilities differ for the Mexican and African American samples when compared to the class label probabilities for the unknown samples? Are these class probabilities telling us something about recent history? Explain why these class probabilities are reasonable with respect to knowledge of recent history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cd4bc-5c1f-407a-aa4c-e9540a27028b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddf562-9c08-4014-8fe0-86758ec66220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9783ddd-c340-477d-8614-3535f1b43b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9cd4512-28f5-4fbe-bfde-7165b5dcdd42",
   "metadata": {},
   "source": [
    "# Deliverable 7 - repeat with a machine learning library\n",
    "\n",
    "> _Implement the assignment using statistical or machine learning libraries in a language of your choice. Compare the results with those obtained above, and provide a discussion as to why you believe your results are different if you found them to be different._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07a1e3-44e3-4f68-83d4-abc870aace47",
   "metadata": {},
   "source": [
    "In this section we repeat the experiments above using scikit-learn. It uses the `sag` solver because it is the closest to the one implemented in our code (a gradient descent algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37e0c1-ec19-4927-a252-09ec474d6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae077ac9-7387-4477-9d54-90a734444a38",
   "metadata": {},
   "source": [
    "## Deliverable 7.1 - effect of lambda on coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319b983-bb5d-41c8-81ce-ea606151928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_sk = []\n",
    "for lmbda in LAMBDAS_TO_TEST:\n",
    "    x, y = read_dataset(standardize=False)\n",
    "    model_sk = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                      linear_model.Ridge(alpha=lmbda,\n",
    "                                                         solver='sag'))\n",
    "    model_sk.fit(x, y)\n",
    "    coef_sk = model_sk.named_steps['ridge'].coef_\n",
    "    betas_sk.append(coef_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30d151-86f1-4c86-86a8-d12fc2202bde",
   "metadata": {},
   "source": [
    "Plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb71a0-bb27-4f5d-9022-1df272b2695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_betas(betas_sk, 'Coefficients x lambda (scikit-learn)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68f77a-71c6-4ae7-87b9-b9715c3b1c40",
   "metadata": {},
   "source": [
    "## Deliverable 7.2 - effect of lambda on MSE (with cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e9fa2-1c5a-4a62-9404-1b3ba3216d55",
   "metadata": {},
   "source": [
    "Fit one model for each value of lambda. Ask scikit-learn to store the cross-validation results (`store_cv_values`) so we can calculate the mean MSE for each lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c5159-8cd1-4452-b4fc-a54e4a65e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_dataset(standardize=False)\n",
    "p = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                           linear_model.RidgeCV(alphas=LAMBDAS_TO_TEST,\n",
    "                           store_cv_values=True))\n",
    "p.fit(x, y)\n",
    "model_sk = p.named_steps['ridgecv']\n",
    "\n",
    "# Mean MSE for each fold\n",
    "mse_sk = model_sk.cv_values_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfd458-ab0d-4e5c-a7e7-799ef6ac8271",
   "metadata": {},
   "source": [
    "Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2e326-73b0-4d78-8962-2d69f2f67e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_sk.flatten(), 'Effect of lambda on MSE (scikit-learn)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479dc0bb-277f-418a-affc-ce0065fab305",
   "metadata": {},
   "source": [
    "## Deliverable 7.3 - the lambda with the smallest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee47f38-bb45-4d1b-8af7-ecab6b09fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The lambda with the smallest MSE is {model_sk.alpha_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938f093-9d7b-4791-b268-16306f8d5908",
   "metadata": {},
   "source": [
    "## Deliverable 7.4 - model parameters for the lambda with the smallest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792191d6-16d0-4265-9b62-0896b1c25c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_dataset(standardize=False)\n",
    "p = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                           linear_model.Ridge(alpha=model_sk.alpha_))\n",
    "p.fit(x, y)\n",
    "coef_sk = p.named_steps['ridge'].coef_\n",
    "for feature, beta in zip(FEATURE_NAMES, coef_sk.flatten()):\n",
    "    print(f'{feature:>10}: {beta:7.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06623007-a5a5-4861-9922-74c4a364a48d",
   "metadata": {},
   "source": [
    "## Deliverable 7.5 - compare with expected real-world results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305bb54-3228-40d5-999f-a764dd1a6499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819889c5-85c0-43dc-9f3f-9a4e0215ceef",
   "metadata": {},
   "source": [
    "## Discussion of differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb8648-46c9-4248-9833-aa414a603a2a",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3d9d6-bc8c-43f8-a38f-d6ec2241a572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
